"""
å›¾è°±æ£€ç´¢å™¨
åŸºäºçŸ¥è¯†å›¾è°±å¢å¼ºè®°å¿†æ£€ç´¢
"""
import json
import sqlite3
from typing import List, Dict, Any, Optional, Tuple
from src.core.logger import logger
from src.core.RAGM.graph_storage import get_graph_storage
from src.core.RAGM.entity_extractor import get_entity_extractor


class GraphRetriever:
    """å›¾è°±å¢å¼ºæ£€ç´¢å™¨"""
    
    def __init__(self):
        self.storage = get_graph_storage()
        self.extractor = get_entity_extractor()
        logger.info("âœ… å›¾è°±æ£€ç´¢å™¨åˆå§‹åŒ–")
    
    async def retrieve_with_graph(
        self,
        user_id: str,
        query: str,
        user_name: str = "ç”¨æˆ·",
        max_results: int = 5
    ) -> str:
        """
        åŸºäºå›¾è°±çš„å¢å¼ºæ£€ç´¢(å¢å¼ºç‰ˆ: æ”¯æŒæ—¶é—´æŸ¥è¯¢å’ŒæŒ‡ä»£æ¶ˆæ­§)
        
        æµç¨‹:
        1. ä»æŸ¥è¯¢ä¸­æå–å…³é”®å®ä½“å’Œæ—¶é—´æŒ‡ä»£(ä½¿ç”¨ LLM)
        2. åœ¨å›¾è°±ä¸­æŸ¥æ‰¾ç›¸å…³å®ä½“(æ”¯æŒåˆ«ååŒ¹é…)
        3. å¦‚æœæœ‰æ—¶é—´æŒ‡ä»£ï¼Œä¼˜å…ˆè¿”å›æœ€è¿‘çš„å…³ç³»
        4. éå†å›¾è°±è·å–å…³è”ä¿¡æ¯
        5. æ ¼å¼åŒ–è¿”å›
        
        Args:
            user_id: ç”¨æˆ· ID
            query: æŸ¥è¯¢æ–‡æœ¬
            user_name: ç”¨æˆ·å
            max_results: æœ€å¤§è¿”å›æ¡æ•°
            
        Returns:
            æ ¼å¼åŒ–çš„å›¾è°±è®°å¿†æ–‡æœ¬
        """
        logger.debug(f"ğŸ” [å›¾è°±æ£€ç´¢] user={user_id}, query={query[:50]}")
        
        # 1. æå–æŸ¥è¯¢ä¸­çš„å…³é”®å®ä½“å’Œæ—¶é—´æŒ‡ä»£
        keywords, time_ref = await self._extract_keywords_with_time(query, user_name)
        
        # å¦‚æœ LLM æå–å¤±è´¥ï¼Œå›é€€åˆ°ç®€å•æå–
        if not keywords:
            keywords = self._extract_keywords_simple(query)
            time_ref = self._extract_time_simple(query)
        
        logger.info(f"ğŸ” [å›¾è°±æ£€ç´¢] æå–å…³é”®è¯: {keywords}, æ—¶é—´æŒ‡ä»£: {time_ref or 'æ— '}")
        
        if not keywords:
            logger.debug(f"   æ— å…³é”®è¯ï¼Œè·³è¿‡æ£€ç´¢")
            return ""
        
        # 2. åœ¨å›¾è°±ä¸­æœç´¢ç›¸å…³å®ä½“ï¼ˆæ”¯æŒåˆ«ååŒ¹é…ï¼‰
        all_entities = []
        for keyword in keywords[:3]:  # æœ€å¤š3ä¸ªå…³é”®è¯
            # ç›´æ¥æœç´¢å®ä½“å
            entities = self.storage.search_entities(user_id, keyword, limit=3)
            
            # æœç´¢åˆ«åï¼ˆé€šè¿‡ properties.aliasesï¼‰
            alias_entities = self._search_by_alias(user_id, keyword)
            
            combined = entities + alias_entities
            
            if combined:
                logger.info(f"   å…³é”®è¯ '{keyword}' æ‰¾åˆ° {len(combined)} ä¸ªå®ä½“:")
                for e in combined:
                    aliases = e.get('properties', {}).get('aliases', [])
                    alias_str = f" (åˆ«å: {', '.join(aliases)})" if aliases else ""
                    logger.info(f"     - {e['entity']} ({e['entity_type']}){alias_str}")
            
            all_entities.extend(combined)
        
        if not all_entities:
            logger.info(f"   æœªæ‰¾åˆ°ç›¸å…³å®ä½“")
            return ""
        
        logger.info(f"   æ€»è®¡æ‰¾åˆ° {len(all_entities)} ä¸ªç›¸å…³å®ä½“")
        
        # 3. è·å–å®ä½“çš„é‚»å±…å…³ç³»ï¼ˆ1-2è·³ï¼‰ï¼Œå¦‚æœæœ‰æ—¶é—´æŒ‡ä»£åˆ™ä¼˜å…ˆæœ€è¿‘çš„
        graph_info = []
        seen_relations = set()
        
        logger.info(f"   å¼€å§‹éå†å›¾è°±å…³ç³»:")
        
        for entity_info in all_entities[:max_results]:
            entity = entity_info["entity"]
            
            # è·å–é‚»å±…
            neighbors = self.storage.get_neighbors(user_id, entity, max_depth=2)
            
            # å¦‚æœæœ‰æ—¶é—´æŒ‡ä»£ï¼ŒæŒ‰æ—¶é—´æˆ³æ’åºï¼ˆæœ€è¿‘çš„ä¼˜å…ˆï¼‰
            if time_ref and neighbors:
                neighbors = self._filter_by_time(neighbors, time_ref)
                logger.info(f"     å®ä½“ '{entity}' æœ‰ {len(neighbors)} ä¸ªé‚»å±…ï¼ˆæ—¶é—´è¿‡æ»¤: {time_ref}ï¼‰")
            elif neighbors:
                logger.info(f"     å®ä½“ '{entity}' æœ‰ {len(neighbors)} ä¸ªé‚»å±…")
            
            for neighbor in neighbors[:5]:  # æ¯ä¸ªå®ä½“æœ€å¤š5ä¸ªé‚»å±…
                relation_key = f"{neighbor['source']}-{neighbor['relation']}-{neighbor['target']}"
                
                if relation_key not in seen_relations:
                    seen_relations.add(relation_key)
                    
                    # æ ¼å¼åŒ–å…³ç³»ï¼ˆè‡ªç„¶è¯­è¨€æè¿°ï¼ŒåŒ…å«æ—¶é—´ä¿¡æ¯ï¼‰
                    time_info = neighbor.get('properties', {}).get('time_ref', '')
                    if time_info:
                        relation_text = f"{time_info}{neighbor['source']}{neighbor['relation']}{neighbor['target']}"
                    else:
                        relation_text = f"{neighbor['source']}{neighbor['relation']}{neighbor['target']}"
                    
                    graph_info.append(relation_text)
                    logger.debug(f"       [{neighbor['depth']}è·³] {relation_text}")
        
        if not graph_info:
            logger.info(f"   æœªæ‰¾åˆ°æœ‰æ•ˆå…³ç³»")
            return ""
        
        # 4. æ ¼å¼åŒ–è¾“å‡ºï¼ˆè‡ªç„¶è¯­è¨€é£æ ¼ï¼‰
        result = "ã€".join(graph_info[:8])  # æœ€å¤š8æ¡ï¼Œç”¨é¡¿å·è¿æ¥
        
        logger.info(f"ğŸ•¸ï¸ [å›¾è°±æ£€ç´¢] è¿”å› {len(graph_info)} æ¡å…³ç³»")
        
        return result
    
    async def _extract_keywords_with_time(self, query: str, user_name: str) -> Tuple[List[str], str]:
        """
        ä½¿ç”¨ LLM æå–å…³é”®å®ä½“å’Œæ—¶é—´æŒ‡ä»£(å¢å¼ºç‰ˆ)
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            user_name: ç”¨æˆ·å
            
        Returns:
            (å…³é”®è¯åˆ—è¡¨, æ—¶é—´æŒ‡ä»£)
        """
        try:
            from src.core.config_manager import ConfigManager
            from src.services.http_client import AsyncHTTPClient
            from src.models.api_types import ChatMessage
            
            ai_config = ConfigManager.get_ai_config()
            organizer = ai_config.organizer
            
            # æ„å»ºæç¤ºè¯
            system_prompt = f"""ä½ æ˜¯å…³é”®è¯æå–åŠ©æ‰‹ã€‚ä»ç”¨æˆ·æ¶ˆæ¯ä¸­æå–å…³é”®å®ä½“å’Œæ—¶é—´æŒ‡ä»£ã€‚

ã€è¾“å‡ºæ ¼å¼ã€‘
ç¬¬ä¸€è¡Œ: 2-3ä¸ªå…³é”®è¯(ç”¨é€—å·åˆ†éš”)
ç¬¬äºŒè¡Œ: æ—¶é—´æŒ‡ä»£(å¦‚"æ˜¨å¤©"ã€"ä¸Šæ¬¡"ã€"æœ€è¿‘"ï¼Œæ²¡æœ‰åˆ™è¾“å‡º"æ— ")

ã€ç¤ºä¾‹1ã€‘
è¾“å…¥: ä½ æ€ä¹ˆçŸ¥é“å¥¹ä¸éœ€è¦
è¾“å‡º:
å¥¹ï¼Œä¸éœ€è¦
æ— 
"""
            
            user_prompt = f"ç”¨æˆ·ï¼ˆ{user_name}ï¼‰è¯´ï¼š{query}\n\nè¯·æå–å…³é”®å®ä½“å’Œæ—¶é—´æŒ‡ä»£ï¼š"
            
            messages = [
                ChatMessage(role="system", content=system_prompt),
                ChatMessage(role="user", content=user_prompt)
            ]
            
            # è·å–ä¾›åº”å•†é…ç½®
            provider_name = getattr(organizer, 'provider', '') or ai_config.common.default_provider
            providers = getattr(ai_config, 'providers', {})
            
            if provider_name in providers:
                provider = providers[provider_name]
                api_base = provider.api_base
                api_key = provider.api_key
                timeout = provider.timeout
            else:
                return [], ""
            
            async with AsyncHTTPClient(timeout=timeout) as client:
                response = await client.chat_completion(
                    api_base=api_base,
                    api_key=api_key,
                    model=organizer.model_name,
                    messages=messages,
                    temperature=0.1,
                    max_tokens=50,
                    timeout=timeout
                )
            
            result = AsyncHTTPClient.parse_completion_response(response)
            
            if result:
                # è§£æä¸¤è¡Œè¾“å‡º
                lines = [line.strip() for line in result.strip().split('\n') if line.strip()]
                
                if len(lines) >= 1:
                    # ç¬¬ä¸€è¡Œï¼šå…³é”®è¯
                    keywords = [k.strip() for k in lines[0].split(',') if k.strip()]
                    
                    # ç¬¬äºŒè¡Œï¼šæ—¶é—´æŒ‡ä»£
                    time_ref = ""
                    if len(lines) >= 2 and lines[1] != "æ— ":
                        time_ref = lines[1]
                    
                    logger.debug(f"   LLM æå–: keywords={keywords}, time_ref={time_ref}")
                    return keywords[:5], time_ref
            
            return [], ""
        
        except Exception as e:
            logger.debug(f"   LLM æå–å¤±è´¥: {e}")
            return [], ""
    
    async def _extract_keywords_llm(self, query: str, user_name: str) -> List[str]:
        """
        ä½¿ç”¨ LLM æå–å…³é”®å®ä½“ï¼ˆæ›´å‡†ç¡®ï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            user_name: ç”¨æˆ·å
            
        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        try:
            from src.core.config_manager import ConfigManager
            from src.services.http_client import AsyncHTTPClient
            from src.models.api_types import ChatMessage
            
            ai_config = ConfigManager.get_ai_config()
            organizer = ai_config.organizer
            
            # æ„å»ºæç¤ºè¯
            system_prompt = f"""ä½ æ˜¯å…³é”®è¯æå–åŠ©æ‰‹ã€‚ä»ç”¨æˆ·æ¶ˆæ¯ä¸­æå–å…³é”®å®ä½“(äººåã€åœ°åã€ç‰©å“ã€äº‹ä»¶ç­‰)ã€‚

ã€è¾“å‡ºæ ¼å¼ã€‘
åªè¾“å‡º2-3ä¸ªå…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚

ã€ç¤ºä¾‹ã€‘
è¾“å…¥: ä½ æ€ä¹ˆçŸ¥é“å¥¹ä¸éœ€è¦
è¾“å‡º: å¥¹ï¼Œä¸éœ€è¦
"""
            
            user_prompt = f"ç”¨æˆ·ï¼ˆ{user_name}ï¼‰è¯´ï¼š{query}\n\nè¯·æå–å…³é”®å®ä½“ï¼š"
            
            messages = [
                ChatMessage(role="system", content=system_prompt),
                ChatMessage(role="user", content=user_prompt)
            ]
            
            # è·å–ä¾›åº”å•†é…ç½®
            provider_name = getattr(organizer, 'provider', '') or ai_config.common.default_provider
            providers = getattr(ai_config, 'providers', {})
            
            if provider_name in providers:
                provider = providers[provider_name]
                api_base = provider.api_base
                api_key = provider.api_key
                timeout = provider.timeout
            else:
                return []
            
            async with AsyncHTTPClient(timeout=timeout) as client:
                response = await client.chat_completion(
                    api_base=api_base,
                    api_key=api_key,
                    model=organizer.model_name,
                    messages=messages,
                    temperature=0.1,
                    max_tokens=50,
                    timeout=timeout
                )
            
            result = AsyncHTTPClient.parse_completion_response(response)
            
            if result:
                # è§£æé€—å·åˆ†éš”çš„å…³é”®è¯
                keywords = [k.strip() for k in result.split(',') if k.strip()]
                logger.debug(f"   LLM æå–: {keywords}")
                return keywords[:5]
            
            return []
        
        except Exception as e:
            logger.debug(f"   LLM æå–å¤±è´¥: {e}")
            return []
    
    def _extract_keywords_simple(self, text: str) -> List[str]:
        """
        æ™ºèƒ½å…³é”®è¯æå–
        
        ç­–ç•¥ï¼š
        1. æå–åè¯ï¼ˆäººåã€åœ°åã€ç‰©å“ç­‰ï¼‰
        2. æå–åŠ¨è¯ï¼ˆåŠ¨ä½œã€è¡Œä¸ºï¼‰
        3. è¿‡æ»¤åœç”¨è¯å’Œæ— æ„ä¹‰è¯
        """
        import re
        
        keywords = []
        
        # 1. æå–ä¸­æ–‡è¯ï¼ˆ2-4å­—çš„è¿ç»­ä¸­æ–‡ï¼‰
        chinese_words = re.findall(r'[\u4e00-\u9fa5]{2,4}', text)
        
        # 2. åœç”¨è¯è¿‡æ»¤ï¼ˆæ‰©å±•ç‰ˆï¼‰
        stopwords = {
            # ç–‘é—®è¯
            'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'å“ªé‡Œ', 'æ€æ ·', 'å¦‚ä½•', 'æ˜¯å¦', 'å¯ä»¥', 'èƒ½ä¸èƒ½', 'æœ‰æ²¡æœ‰',
            'ä¸ºä½•', 'ä½•æ—¶', 'ä½•åœ°', 'è°çš„', 'å“ªä¸ª', 'å“ªäº›',
            # ä»£è¯
            'ä½ çš„', 'æˆ‘çš„', 'ä»–çš„', 'å¥¹çš„', 'å®ƒçš„', 'æˆ‘ä»¬', 'ä½ ä»¬', 'ä»–ä»¬',
            'è¿™ä¸ª', 'é‚£ä¸ª', 'è¿™äº›', 'é‚£äº›', 'è¿™æ ·', 'é‚£æ ·',
            # åŠ¨è¯
            'çŸ¥é“', 'è§‰å¾—', 'è®¤ä¸º', 'æ„Ÿè§‰', 'æƒ³è¦', 'å¸Œæœ›', 'éœ€è¦', 'åº”è¯¥',
            # å…¶ä»–
            'ä¸æ˜¯', 'æ²¡æœ‰', 'ä¸è¦', 'ä¸ä¼š', 'ä¸èƒ½', 'è¿˜æ˜¯', 'æˆ–è€…', 'ä½†æ˜¯',
            'å› ä¸º', 'æ‰€ä»¥', 'å¦‚æœ', 'è™½ç„¶', 'ç„¶å', 'æ¥ç€', 'äºæ˜¯'
        }
        
        # 3. è¿‡æ»¤å¹¶å»é‡
        seen = set()
        for word in chinese_words:
            if word not in stopwords and word not in seen and len(word) >= 2:
                keywords.append(word)
                seen.add(word)
        
        # 4. æå–è‹±æ–‡è¯ï¼ˆ3å­—æ¯ä»¥ä¸Šï¼‰
        english_words = re.findall(r'[a-zA-Z]{3,}', text)
        for word in english_words:
            if word.lower() not in seen:
                keywords.append(word)
                seen.add(word.lower())
        
        # 5. é™åˆ¶æ•°é‡
        return keywords[:5]
    
    def _extract_time_simple(self, text: str) -> str:
        """
        ç®€å•æå–æ—¶é—´æŒ‡ä»£
        
        Returns:
            æ—¶é—´æŒ‡ä»£è¯ï¼ˆå¦‚"æ˜¨å¤©"ã€"ä¸Šæ¬¡"ï¼‰ï¼Œæ²¡æœ‰åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        time_keywords = [
            'æ˜¨å¤©', 'å‰å¤©', 'ä¸Šæ¬¡', 'æœ€è¿‘', 'åˆšæ‰', 'åˆšåˆš', 'ä¹‹å‰', 
            'ä¸Šå‘¨', 'ä¸Šä¸ªæœˆ', 'å»å¹´', 'é‚£å¤©', 'é‚£æ—¶', 'å½“æ—¶'
        ]
        
        for keyword in time_keywords:
            if keyword in text:
                return keyword
        
        return ""
    
    def _search_by_alias(self, user_id: str, alias: str) -> List[Dict[str, Any]]:
        """
        é€šè¿‡åˆ«åæœç´¢å®ä½“
        
        Args:
            user_id: ç”¨æˆ· ID
            alias: åˆ«å(å¦‚"å¥¹"ã€"é‚£ä¸ªäºº")
            
        Returns:
            åŒ¹é…çš„å®ä½“åˆ—è¡¨
        """
        conn = sqlite3.connect(str(self.storage.db_path))
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT entity, entity_type, properties, updated_at
            FROM nodes
            WHERE user_id = ? AND properties LIKE ?
            ORDER BY updated_at DESC
            LIMIT 5
        """, (user_id, f'%"{alias}"%'))
        
        results = []
        for row in cursor.fetchall():
            entity, entity_type, props, updated_at = row
            props_dict = json.loads(props) if props else {}
            
            # éªŒè¯åˆ«åç¡®å®åœ¨åˆ—è¡¨ä¸­
            aliases = props_dict.get('aliases', [])
            if alias in aliases:
                results.append({
                    "entity": entity,
                    "entity_type": entity_type,
                    "properties": props_dict,
                    "updated_at": updated_at
                })
        
        conn.close()
        return results
    
    def _filter_by_time(self, neighbors: List[Dict[str, Any]], time_ref: str) -> List[Dict[str, Any]]:
        """
        æ ¹æ®æ—¶é—´æŒ‡ä»£è¿‡æ»¤å…³ç³»
        
        ç­–ç•¥:
        - "ä¸Šæ¬¡"/"æœ€è¿‘"/"åˆšæ‰" -> è¿”å›æœ€è¿‘çš„å…³ç³»(æŒ‰æ—¶é—´æˆ³æ’åº)
        - "æ˜¨å¤©"/"å‰å¤©" -> è¿”å›å¯¹åº”æ—¶é—´èŒƒå›´çš„å…³ç³»
        - å…¶ä»– -> ä¸è¿‡æ»¤
        
        Args:
            neighbors: é‚»å±…å…³ç³»åˆ—è¡¨
            time_ref: æ—¶é—´æŒ‡ä»£
            
        Returns:
            è¿‡æ»¤åçš„å…³ç³»åˆ—è¡¨
        """
        import time as time_module
        
        current_time = int(time_module.time())
        
        # å®šä¹‰æ—¶é—´èŒƒå›´ï¼ˆç§’ï¼‰
        time_ranges = {
            'åˆšæ‰': 3600,           # 1å°æ—¶å†…
            'åˆšåˆš': 3600,
            'æœ€è¿‘': 86400 * 7,      # 7å¤©å†…
            'æ˜¨å¤©': (86400, 86400 * 2),  # 1-2å¤©å‰
            'å‰å¤©': (86400 * 2, 86400 * 3),  # 2-3å¤©å‰
            'ä¸Šæ¬¡': 86400 * 30,     # 30å¤©å†…
            'ä¹‹å‰': 86400 * 30,
        }
        
        # å¦‚æœæ—¶é—´æŒ‡ä»£ä¸åœ¨èŒƒå›´å†…ï¼Œä¸è¿‡æ»¤
        if time_ref not in time_ranges:
            return neighbors
        
        # æå–æœ‰æ—¶é—´æˆ³çš„å…³ç³»
        timed_neighbors = []
        for neighbor in neighbors:
            props = neighbor.get('properties', {})
            timestamp = props.get('timestamp')
            
            if timestamp:
                neighbor['_timestamp'] = timestamp
                timed_neighbors.append(neighbor)
        
        # å¦‚æœæ²¡æœ‰æ—¶é—´æˆ³
        if not timed_neighbors:
            return neighbors
        
        # æ ¹æ®æ—¶é—´æŒ‡ä»£è¿‡æ»¤
        time_range = time_ranges[time_ref]
        
        if isinstance(time_range, tuple):
            # èŒƒå›´è¿‡æ»¤ï¼ˆå¦‚"æ˜¨å¤©"ï¼‰
            min_time, max_time = time_range
            filtered = [
                n for n in timed_neighbors
                if min_time <= (current_time - n['_timestamp']) < max_time
            ]
        else:
            # å•ä¸€èŒƒå›´è¿‡æ»¤ï¼ˆå¦‚"æœ€è¿‘"ï¼‰
            filtered = [
                n for n in timed_neighbors
                if (current_time - n['_timestamp']) <= time_range
            ]
        
        # å¦‚æœè¿‡æ»¤åä¸ºç©ºï¼Œè¿”å›æœ€è¿‘çš„å‡ æ¡
        if not filtered:
            timed_neighbors.sort(key=lambda x: x['_timestamp'], reverse=True)
            return timed_neighbors[:5]
        
        # æŒ‰æ—¶é—´æ’åºï¼ˆæœ€è¿‘çš„ä¼˜å…ˆï¼‰
        filtered.sort(key=lambda x: x['_timestamp'], reverse=True)
        
        return filtered
    
    async def add_dialogue_to_graph(
        self,
        user_id: str,
        user_message: str,
        bot_reply: str,
        user_name: str = "ç”¨æˆ·"
    ):
        """
        å°†å¯¹è¯æ·»åŠ åˆ°çŸ¥è¯†å›¾è°±(å¢å¼ºç‰ˆ: æ”¯æŒæ—¶é—´å’Œåˆ«å)
        
        Args:
            user_id: ç”¨æˆ· ID
            user_message: ç”¨æˆ·æ¶ˆæ¯
            bot_reply: Bot å›å¤
            user_name: ç”¨æˆ·å
        """
        try:
            logger.info(f"ğŸ“Š [å›¾è°±æ„å»º] å¼€å§‹æå–å®ä½“å’Œå…³ç³»")
            logger.debug(f"   ç”¨æˆ·æ¶ˆæ¯: {user_message[:50]}")
            logger.debug(f"   Botå›å¤: {bot_reply[:50]}")
            
            # æå–å®ä½“å’Œå…³ç³»(å¢å¼ºç‰ˆ)
            extracted = await self.extractor.extract_from_dialogue(
                user_message, bot_reply, user_name
            )
            
            entities = extracted.get("entities", [])
            relations = extracted.get("relations", [])
            time_context = extracted.get("time_context", "")
            
            if not entities and not relations:
                logger.info(f"ğŸ“Š [å›¾è°±æ„å»º] æ— å®ä½“æˆ–å…³ç³»ï¼Œè·³è¿‡")
                return
            
            # æ·»åŠ å®ä½“åˆ°å›¾è°±ï¼ˆåŒ…å«åˆ«åï¼‰
            logger.info(f"ğŸ“Š [å›¾è°±æ„å»º] æ·»åŠ  {len(entities)} ä¸ªå®ä½“:")
            for entity in entities:
                alias = entity.get("alias", "")
                self.storage.add_node(
                    user_id=user_id,
                    entity=entity["name"],
                    entity_type=entity.get("type", "å…¶ä»–"),
                    alias=alias if alias else None
                )
                
                alias_info = f" (åˆ«å: {alias})" if alias else ""
                logger.info(f"     + å®ä½“: {entity['name']} ({entity.get('type', 'å…¶ä»–')}){alias_info}")
            
            # æ·»åŠ å…³ç³»åˆ°å›¾è°±ï¼ˆåŒ…å«æ—¶é—´æŒ‡ä»£ï¼‰
            logger.info(f"ğŸ“Š [å›¾è°±æ„å»º] æ·»åŠ  {len(relations)} ä¸ªå…³ç³»:")
            for relation in relations:
                time_ref = relation.get("time_ref", "") or time_context
                self.storage.add_edge(
                    user_id=user_id,
                    source=relation["source"],
                    target=relation["target"],
                    relation=relation["relation"],
                    time_ref=time_ref if time_ref else None
                )
                
                time_info = f" [{time_ref}]" if time_ref else ""
                logger.info(f"     + å…³ç³»: {relation['source']} â†’ {relation['relation']} â†’ {relation['target']}{time_info}")
            
            logger.info(f"âœ… [å›¾è°±æ„å»º] å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ å›¾è°±æ„å»ºå¤±è´¥: {e}", exc_info=True)


# å…¨å±€å•ä¾‹
_graph_retriever: Optional[GraphRetriever] = None


def get_graph_retriever() -> GraphRetriever:
    """è·å–å…¨å±€å›¾è°±æ£€ç´¢å™¨å•ä¾‹"""
    global _graph_retriever
    if _graph_retriever is None:
        _graph_retriever = GraphRetriever()
    return _graph_retriever
