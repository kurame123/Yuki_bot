"""
æ£€ç´¢ç­–ç•¥æ¨¡å— - æœˆä»£é›ªçŸ¥è¯†åº“å¤šå±‚æ¬¡æ£€ç´¢ä¼˜åŒ–

å®ç°åŠŸèƒ½ï¼š
1. å¤šå±‚æ¬¡æ£€ç´¢æ¶æ„ï¼ˆç²¾ç¡®åŒ¹é… + è¯­ä¹‰ç›¸ä¼¼åº¦ + ä¸Šä¸‹æ–‡ç›¸å…³æ€§ï¼‰
2. è§’è‰²ä¸“å±å…³é”®è¯æƒé‡
3. åœºæ™¯æ„ŸçŸ¥æ£€ç´¢
4. æ£€ç´¢ç»“æœåå¤„ç†ä¸é‡æ’åº
5. åŠ¨æ€æƒé‡è°ƒæ•´
"""
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import re
import time

from src.core.logger import logger


class SceneType(Enum):
    """å¯¹è¯åœºæ™¯ç±»å‹"""
    IDENTITY = "identity"       # èº«ä»½è¯¢é—®
    EMOTION = "emotion"         # æƒ…æ„Ÿè¡¨è¾¾
    DAILY = "daily"             # æ—¥å¸¸äº¤æµ
    DEEP = "deep"               # æ·±åº¦å¯¹è¯
    GREETING = "greeting"       # é—®å€™å¯’æš„
    UNKNOWN = "unknown"         # æœªçŸ¥åœºæ™¯


@dataclass
class RetrievalResult:
    """æ£€ç´¢ç»“æœæ•°æ®ç±»"""
    content: str
    source: str
    original_score: float
    final_score: float
    match_type: str  # "keyword", "semantic", "hybrid"
    matched_keywords: List[str]


class RetrievalStrategy:
    """
    å¤šå±‚æ¬¡æ£€ç´¢ç­–ç•¥
    
    æ£€ç´¢æµç¨‹ï¼š
    1. åœºæ™¯è¯†åˆ« â†’ ç¡®å®šæ£€ç´¢é‡ç‚¹
    2. å…³é”®è¯åŒ¹é… â†’ ç²¾ç¡®åŒ¹é…åŠ åˆ†
    3. è¯­ä¹‰æ£€ç´¢ â†’ å‘é‡ç›¸ä¼¼åº¦
    4. ç»“æœé‡æ’åº â†’ ç»¼åˆè¯„åˆ†
    5. åå¤„ç†è¿‡æ»¤ â†’ è´¨é‡ä¿è¯
    """
    
    # ============ è§’è‰²ä¸“å±å…³é”®è¯æƒé‡é…ç½® ============
    KEYWORD_WEIGHTS = {
        # æ ¸å¿ƒè§’è‰²å…³é”®è¯ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        "è§’è‰²æ ¸å¿ƒ": {
            "æœˆä»£é›ª": 10.0,
            "å°é›ª": 8.0,
            "æœˆé›ª": 8.0,
            "æœˆä»£": 7.0,
        },
        # èº«ä»½ç›¸å…³
        "èº«ä»½èƒŒæ™¯": {
            "å¤§é­”å¥³": 8.0,
            "é­”å¥³å› å­": 7.0,
            "é­”å¥³ç§æ—": 8.0,
            "æœ€åå¹¸å­˜è€…": 9.0,
            "é­”å¥³å®¡åˆ¤": 7.0,
            "ç­ä¸–è®¡åˆ’": 6.0,
            "å¤ä»‡": 5.0,
        },
        # è§’è‰²å…³ç³»
        "è§’è‰²å…³ç³»": {
            "è‰¾ç›": 4.0,
            "å¸Œç½—": 4.0,
            "æ¨±ç¾½è‰¾ç›": 6.0,
            "äºŒé˜¶å ‚å¸Œç½—": 6.0,
        },
        # æ€§æ ¼ç‰¹å¾
        "æ€§æ ¼ç‰¹å¾": {
            "å­¤ç‹¬": 5.0,
            "å†·æ¼ ": 4.0,
            "ç†æ€§": 4.0,
            "çŸ›ç›¾": 5.0,
            "ä¼ªè£…": 5.0,
            "è§‚å¯Ÿ": 4.0,
        },
    }
    
    # ============ åŒä¹‰è¯æ‰©å±•æ˜ å°„ ============
    SYNONYM_MAP = {
        "æœˆä»£é›ª": ["æœˆé›ª", "é›ª", "å°é›ª", "æœˆä»£"],
        "é­”å¥³": ["å¤§é­”å¥³", "é­”å¥³å› å­", "é­”å¥³ç§æ—", "æœ€åå¹¸å­˜è€…"],
        "æœ‹å‹": ["åŒä¼´", "ä¼™ä¼´", "å‹äºº"],
        "å­¤ç‹¬": ["å¯‚å¯", "ç‹¬è‡ª", "ä¸€ä¸ªäºº"],
        "å¤ä»‡": ["æŠ¥ä»‡", "ä»‡æ¨", "ç­ä¸–"],
    }
    
    # ============ è´Ÿå‘è¿‡æ»¤å…³é”®è¯ ============
    NEGATIVE_KEYWORDS = {
        # å…¶ä»–è§’è‰²ç‰¹å¾ï¼ˆé¿å…æ··æ·†ï¼‰
        "å…¶ä»–è§’è‰²": ["ä¾¦æ¢", "æ˜æ˜Ÿ", "è‰ºäºº", "æ¼”å‘˜", "dayo", "æ…µæ‡’", "å°¾éŸ³"],
        # æ— å…³ä¸»é¢˜
        "æ— å…³ä¸»é¢˜": ["æ¨ç†", "è¡¨æ¼”", "æ¼”è‰º", "çŠ¯ç½ªè°ƒæŸ¥"],
    }
    
    # ============ åœºæ™¯è¯†åˆ«å…³é”®è¯ ============
    SCENE_KEYWORDS = {
        SceneType.IDENTITY: ["ä½ æ˜¯è°", "çœŸå®èº«ä»½", "å¤§é­”å¥³", "é­”å¥³", "èº«ä»½", "ä½ å«ä»€ä¹ˆ", "ä»‹ç»ä¸€ä¸‹è‡ªå·±"],
        SceneType.EMOTION: ["å–œæ¬¢", "çˆ±", "è®¨åŒ", "æ„Ÿè§‰", "å¿ƒæƒ…", "å¼€å¿ƒ", "éš¾è¿‡", "å­¤ç‹¬", "å¯‚å¯"],
        SceneType.DAILY: ["ä»Šå¤©", "æ—©ä¸Š", "æ™šä¸Š", "åƒ", "åšä»€ä¹ˆ", "åœ¨å¹²å˜›", "å¤©æ°”"],
        SceneType.DEEP: ["äººç”Ÿ", "æ„ä¹‰", "ä¸ºä»€ä¹ˆ", "å­˜åœ¨", "å‘½è¿", "æœªæ¥", "è¿‡å»"],
        SceneType.GREETING: ["ä½ å¥½", "æ—©å®‰", "æ™šå®‰", "å—¨", "åœ¨å—", "hello", "hi"],
    }
    
    # ============ åœºæ™¯å¯¹åº”çš„æ£€ç´¢é‡ç‚¹ ============
    SCENE_RETRIEVAL_FOCUS = {
        SceneType.IDENTITY: ["èº«ä»½èƒŒæ™¯", "è§’è‰²æ ¸å¿ƒ"],
        SceneType.EMOTION: ["æ€§æ ¼ç‰¹å¾", "è§’è‰²å…³ç³»"],
        SceneType.DAILY: ["æ€§æ ¼ç‰¹å¾"],
        SceneType.DEEP: ["èº«ä»½èƒŒæ™¯", "æ€§æ ¼ç‰¹å¾"],
        SceneType.GREETING: ["æ€§æ ¼ç‰¹å¾"],
        SceneType.UNKNOWN: ["è§’è‰²æ ¸å¿ƒ", "æ€§æ ¼ç‰¹å¾"],
    }
    
    def __init__(self, similarity_threshold: float = 0.5):
        """
        åˆå§‹åŒ–æ£€ç´¢ç­–ç•¥
        
        Args:
            similarity_threshold: è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆä¼˜åŒ–åæå‡åˆ°0.5ï¼‰
        """
        self.similarity_threshold = similarity_threshold
        self.keyword_weight_ratio = 0.4  # å…³é”®è¯åŒ¹é…æƒé‡
        self.semantic_weight_ratio = 0.6  # è¯­ä¹‰ç›¸ä¼¼åº¦æƒé‡
        
        # æ„å»ºæ‰å¹³åŒ–çš„å…³é”®è¯æƒé‡è¡¨
        self._flat_keyword_weights = {}
        for category, keywords in self.KEYWORD_WEIGHTS.items():
            for kw, weight in keywords.items():
                self._flat_keyword_weights[kw] = (weight, category)
        
        logger.info(f"ğŸ¯ æ£€ç´¢ç­–ç•¥åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   - ç›¸ä¼¼åº¦é˜ˆå€¼: {self.similarity_threshold}")
        logger.info(f"   - å…³é”®è¯æƒé‡æ¯”: {self.keyword_weight_ratio}")
        logger.info(f"   - è¯­ä¹‰æƒé‡æ¯”: {self.semantic_weight_ratio}")

    def identify_scene(self, query: str, conversation_history: Optional[List[str]] = None) -> SceneType:
        """
        è¯†åˆ«å¯¹è¯åœºæ™¯
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            conversation_history: å¯¹è¯å†å²ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            åœºæ™¯ç±»å‹
        """
        query_lower = query.lower()
        
        # æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥åœºæ™¯å…³é”®è¯
        scene_scores = {}
        for scene_type, keywords in self.SCENE_KEYWORDS.items():
            score = sum(1 for kw in keywords if kw in query_lower)
            if score > 0:
                scene_scores[scene_type] = score
        
        if scene_scores:
            # è¿”å›å¾—åˆ†æœ€é«˜çš„åœºæ™¯
            best_scene = max(scene_scores, key=scene_scores.get)
            logger.debug(f"ğŸ­ åœºæ™¯è¯†åˆ«: {query[:20]}... â†’ {best_scene.value}")
            return best_scene
        
        return SceneType.UNKNOWN
    
    def extract_keywords(self, text: str) -> List[Tuple[str, float, str]]:
        """
        ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯åŠå…¶æƒé‡
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            [(å…³é”®è¯, æƒé‡, ç±»åˆ«), ...]
        """
        found_keywords = []
        
        for keyword, (weight, category) in self._flat_keyword_weights.items():
            if keyword in text:
                found_keywords.append((keyword, weight, category))
        
        # æŒ‰æƒé‡é™åºæ’åˆ—
        found_keywords.sort(key=lambda x: x[1], reverse=True)
        return found_keywords
    
    def expand_query(self, query: str) -> List[str]:
        """
        æŸ¥è¯¢æ‰©å±• - æ·»åŠ åŒä¹‰è¯
        
        Args:
            query: åŸå§‹æŸ¥è¯¢
            
        Returns:
            æ‰©å±•åçš„æŸ¥è¯¢è¯åˆ—è¡¨
        """
        expanded = [query]
        
        for key, synonyms in self.SYNONYM_MAP.items():
            if key in query:
                expanded.extend(synonyms)
        
        return list(set(expanded))
    
    def calculate_keyword_score(self, content: str, query: str, scene: SceneType) -> Tuple[float, List[str]]:
        """
        è®¡ç®—å…³é”®è¯åŒ¹é…å¾—åˆ†
        
        Args:
            content: æ£€ç´¢åˆ°çš„å†…å®¹
            query: ç”¨æˆ·æŸ¥è¯¢
            scene: å¯¹è¯åœºæ™¯
            
        Returns:
            (å¾—åˆ†, åŒ¹é…çš„å…³é”®è¯åˆ—è¡¨)
        """
        score = 0.0
        matched_keywords = []
        
        # 1. æ£€æŸ¥å†…å®¹ä¸­çš„å…³é”®è¯
        content_keywords = self.extract_keywords(content)
        
        # 2. æ ¹æ®åœºæ™¯è°ƒæ•´æƒé‡
        focus_categories = self.SCENE_RETRIEVAL_FOCUS.get(scene, ["è§’è‰²æ ¸å¿ƒ"])
        
        for keyword, weight, category in content_keywords:
            # åœºæ™¯ç›¸å…³çš„ç±»åˆ«åŠ æˆ
            if category in focus_categories:
                weight *= 1.3
            
            # å¦‚æœæŸ¥è¯¢ä¸­ä¹ŸåŒ…å«è¯¥å…³é”®è¯ï¼Œé¢å¤–åŠ æˆ
            if keyword in query:
                weight *= 1.5
            
            score += weight
            matched_keywords.append(keyword)
        
        # 3. è§’è‰²åç›´æ¥åŒ¹é…çš„é¢å¤–åŠ åˆ†
        if "æœˆä»£é›ª" in content:
            score += 3.0
            if "æœˆä»£é›ª" not in matched_keywords:
                matched_keywords.append("æœˆä»£é›ª")
        
        # å½’ä¸€åŒ–åˆ° 0-1 èŒƒå›´ï¼ˆå‡è®¾æœ€å¤§å¯èƒ½å¾—åˆ†çº¦ä¸º 30ï¼‰
        normalized_score = min(score / 30.0, 1.0)
        
        return normalized_score, matched_keywords
    
    def check_negative_filter(self, content: str) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥è¿‡æ»¤è¯¥å†…å®¹ï¼ˆè´Ÿå‘è¿‡æ»¤ï¼‰
        
        Args:
            content: æ£€ç´¢å†…å®¹
            
        Returns:
            True = åº”è¯¥è¿‡æ»¤æ‰, False = ä¿ç•™
        """
        for category, keywords in self.NEGATIVE_KEYWORDS.items():
            for kw in keywords:
                if kw in content and "æœˆä»£é›ª" not in content:
                    # å¦‚æœåŒ…å«è´Ÿå‘å…³é”®è¯ä¸”ä¸åŒ…å«æœˆä»£é›ªï¼Œè¿‡æ»¤æ‰
                    logger.debug(f"ğŸš« è´Ÿå‘è¿‡æ»¤: åŒ…å« '{kw}' (ç±»åˆ«: {category})")
                    return True
        return False
    
    def check_content_completeness(self, content: str) -> float:
        """
        æ£€æŸ¥å†…å®¹å®Œæ•´æ€§
        
        Args:
            content: æ£€ç´¢å†…å®¹
            
        Returns:
            å®Œæ•´æ€§å¾—åˆ† (0-1)
        """
        score = 1.0
        
        # æ£€æŸ¥æ˜¯å¦è¢«æˆªæ–­ï¼ˆä»¥ä¸å®Œæ•´çš„æ ‡ç‚¹ç»“å°¾ï¼‰
        if content.endswith(('ï¼Œ', 'ã€', 'ï¼š', 'çš„', 'æ˜¯', 'åœ¨', 'å’Œ')):
            score -= 0.2
        
        # æ£€æŸ¥é•¿åº¦ï¼ˆå¤ªçŸ­å¯èƒ½æ˜¯ç¢ç‰‡ï¼‰
        if len(content) < 20:
            score -= 0.3
        elif len(content) < 50:
            score -= 0.1
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å®Œæ•´å¥å­ï¼ˆæœ‰å¥å·ã€é—®å·ã€æ„Ÿå¹å·ï¼‰
        if not any(p in content for p in ['ã€‚', 'ï¼', 'ï¼Ÿ', '!', '?', '.']):
            score -= 0.1
        
        return max(score, 0.0)
    
    def rerank_results(
        self,
        results: List[Dict[str, Any]],
        query: str,
        scene: SceneType
    ) -> List[RetrievalResult]:
        """
        é‡æ’åºæ£€ç´¢ç»“æœ
        
        Args:
            results: åŸå§‹æ£€ç´¢ç»“æœ [{"content": str, "source": str, "similarity": float}, ...]
            query: ç”¨æˆ·æŸ¥è¯¢
            scene: å¯¹è¯åœºæ™¯
            
        Returns:
            é‡æ’åºåçš„ç»“æœåˆ—è¡¨
        """
        reranked = []
        
        for result in results:
            content = result.get("content", "")
            source = result.get("source", "Unknown")
            original_score = result.get("similarity", 0.0)
            
            # 1. è´Ÿå‘è¿‡æ»¤
            if self.check_negative_filter(content):
                continue
            
            # 2. è®¡ç®—å…³é”®è¯å¾—åˆ†
            keyword_score, matched_keywords = self.calculate_keyword_score(content, query, scene)
            
            # 3. è®¡ç®—å†…å®¹å®Œæ•´æ€§
            completeness = self.check_content_completeness(content)
            
            # 4. ç»¼åˆè¯„åˆ†
            # æœ€ç»ˆå¾—åˆ† = å…³é”®è¯å¾—åˆ† * 0.4 + è¯­ä¹‰å¾—åˆ† * 0.6 + å®Œæ•´æ€§åŠ æˆ
            final_score = (
                keyword_score * self.keyword_weight_ratio +
                original_score * self.semantic_weight_ratio +
                completeness * 0.1  # å®Œæ•´æ€§å°å¹…åŠ æˆ
            )
            
            # ç¡®å®šåŒ¹é…ç±»å‹
            if keyword_score > 0.3 and original_score > 0.5:
                match_type = "hybrid"
            elif keyword_score > 0.3:
                match_type = "keyword"
            else:
                match_type = "semantic"
            
            reranked.append(RetrievalResult(
                content=content,
                source=source,
                original_score=original_score,
                final_score=final_score,
                match_type=match_type,
                matched_keywords=matched_keywords
            ))
        
        # æŒ‰æœ€ç»ˆå¾—åˆ†é™åºæ’åˆ—
        reranked.sort(key=lambda x: x.final_score, reverse=True)
        
        return reranked
    
    def filter_by_threshold(
        self,
        results: List[RetrievalResult],
        min_score: Optional[float] = None
    ) -> List[RetrievalResult]:
        """
        æ ¹æ®é˜ˆå€¼è¿‡æ»¤ç»“æœ
        
        Args:
            results: é‡æ’åºåçš„ç»“æœ
            min_score: æœ€ä½åˆ†æ•°é˜ˆå€¼ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®å€¼ï¼‰
            
        Returns:
            è¿‡æ»¤åçš„ç»“æœ
        """
        if min_score is None:
            min_score = self.similarity_threshold
        
        filtered = [r for r in results if r.final_score >= min_score]
        
        logger.debug(f"ğŸ” é˜ˆå€¼è¿‡æ»¤: {len(results)} â†’ {len(filtered)} (é˜ˆå€¼: {min_score})")
        
        return filtered
    
    def format_results(self, results: List[RetrievalResult], max_results: int = 3) -> str:
        """
        æ ¼å¼åŒ–æ£€ç´¢ç»“æœä¸ºå­—ç¬¦ä¸²
        
        Args:
            results: æ£€ç´¢ç»“æœåˆ—è¡¨
            max_results: æœ€å¤§è¿”å›æ•°é‡
            
        Returns:
            æ ¼å¼åŒ–çš„å­—ç¬¦ä¸²
        """
        if not results:
            return ""
        
        # å–å‰ N æ¡
        top_results = results[:max_results]
        
        lines = []
        for i, result in enumerate(top_results, 1):
            # ç§»é™¤æ–‡ä»¶æ‰©å±•åä½œä¸ºæ ‡é¢˜
            title = result.source.rsplit('.', 1)[0] if '.' in result.source else result.source
            
            # åªè¾“å‡ºæ ‡é¢˜å’Œå†…å®¹ï¼Œçœç•¥è°ƒè¯•ä¿¡æ¯
            lines.append(f"{i}. {title}ï¼š{result.content}")
        
        return "\n".join(lines)


# å…¨å±€å•ä¾‹
_retrieval_strategy: Optional[RetrievalStrategy] = None


def get_retrieval_strategy() -> RetrievalStrategy:
    """è·å–å…¨å±€æ£€ç´¢ç­–ç•¥å•ä¾‹"""
    global _retrieval_strategy
    if _retrieval_strategy is None:
        _retrieval_strategy = RetrievalStrategy()
    return _retrieval_strategy


def reset_retrieval_strategy() -> None:
    """é‡ç½®æ£€ç´¢ç­–ç•¥å•ä¾‹ï¼ˆç”¨äºçƒ­é‡è½½é…ç½®ï¼‰"""
    global _retrieval_strategy
    _retrieval_strategy = None
    logger.info("ğŸ”„ æ£€ç´¢ç­–ç•¥å·²é‡ç½®ï¼Œä¸‹æ¬¡ä½¿ç”¨æ—¶å°†é‡æ–°åŠ è½½é…ç½®")
